# JESSY Configuration Example
# Copy this to .env and fill in your API keys

# ============================================
# LLM API Keys (at least one required)
# ============================================

# OpenAI API Key (for GPT-4, GPT-3.5)
# Get yours at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...

# Anthropic API Key (for Claude)
# Get yours at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...

# ============================================
# LLM Configuration
# ============================================

# Provider selection: openai, anthropic, or auto
# auto = use Anthropic if available, otherwise OpenAI
LLM_PROVIDER=auto

# Model name
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
LLM_MODEL=claude-3-sonnet-20240229

# API request timeout in seconds
LLM_TIMEOUT_SECS=30

# Maximum retries for failed API calls
LLM_MAX_RETRIES=3

# ============================================
# System Limits
# ============================================

# Memory limit in MB (minimum: 100, default: 500)
MEMORY_LIMIT_MB=500

# Maximum iterations per query (range: 1-9, default: 9)
MAX_ITERATIONS=9

# Query timeout in seconds (minimum: 5, default: 30)
QUERY_TIMEOUT_SECS=30

# Maximum concurrent queries (default: 10)
MAX_CONCURRENT_QUERIES=10

# ============================================
# Operational Configuration
# ============================================

# Environment: development or production
RUST_ENV=development

# Enable debug mode (true/false)
DEBUG=false

# Log level: error, warn, info, debug, trace
RUST_LOG=info
