# ðŸ”¥ Thor Training Setup Guide

## Quick Start (5 dakika)

### 1. Thor'a BaÄŸlan
```bash
ssh jensen@192.168.88.55
# Password: jensen
```

### 2. Dizin OluÅŸtur
```bash
mkdir -p ~/jessy-training
cd ~/jessy-training
```

### 3. DosyalarÄ± Kopyala (Mac'ten)

**Yeni terminal aÃ§ (Mac'te):**
```bash
# Training script'i kopyala
scp training/train_on_thor.py jensen@192.168.88.55:~/jessy-training/

# Training data'yÄ± kopyala
scp training/datasets/jessy_maximum_train.jsonl jensen@192.168.88.55:~/jessy-training/
scp training/datasets/jessy_maximum_val.jsonl jensen@192.168.88.55:~/jessy-training/
```

### 4. Dependencies Kur (Thor'da)
```bash
# Thor'da Ã§alÄ±ÅŸtÄ±r
python3 -m pip install --user torch transformers peft datasets accelerate bitsandbytes
```

### 5. Training BaÅŸlat
```bash
# Foreground (ekranda gÃ¶rmek iÃ§in)
python3 train_on_thor.py

# VEYA Background (kapanmaz)
nohup python3 train_on_thor.py > training.log 2>&1 &

# Log'u takip et
tail -f training.log
```

## Beklenen Ã‡Ä±ktÄ±

```
======================================================================
ðŸ”¥ JESSY Training on Thor
======================================================================
âœ… PyTorch: 2.9.0
âœ… CUDA: 13.0
âœ… GPU Count: 1
âœ… GPU 0: NVIDIA Thor
   Memory: XX.X GB
======================================================================
ðŸ“¥ Loading model: Qwen/Qwen2.5-3B-Instruct
âœ… Model loaded
ðŸ”§ Applying LoRA configuration...
ðŸ“Š Trainable params: 41,943,040 (1.32%)
ðŸ“Š Total params: 3,174,400,000
âœ… LoRA applied
ðŸ“š Loading datasets...
ðŸ“Š Train samples: XXXX
ðŸ“Š Validation samples: XXX
ðŸ”„ Formatting datasets...
ðŸ”„ Tokenizing datasets...
âœ… Datasets ready
======================================================================
ðŸš€ Starting Training
======================================================================
ðŸ“Š Epochs: 3
ðŸ“Š Batch size: 8
ðŸ“Š Gradient accumulation: 4
ðŸ“Š Effective batch size: 32
ðŸ“Š Learning rate: 0.0002
======================================================================
[Training progress...]
```

## Training SÃ¼resi

- **GPU**: NVIDIA Thor
- **Model**: Qwen2.5-3B (3 billion parameters)
- **LoRA Rank**: 32
- **Epochs**: 3
- **Batch Size**: 32 (effective)

**Tahmini SÃ¼re**: 30-60 dakika

## Training SÄ±rasÄ±nda

### GPU KullanÄ±mÄ±nÄ± Ä°zle
```bash
# Yeni terminal aÃ§
watch -n 1 nvidia-smi
```

### Log'u Ä°zle
```bash
tail -f training.log
```

### Training'i Durdur
```bash
# Process ID bul
ps aux | grep train_on_thor

# Durdur
kill <PID>
```

## Training Bittikten Sonra

### Model DosyalarÄ±nÄ± Kontrol Et
```bash
ls -lh ~/jessy-training/jessy-thor-output/
```

### Model'i Mac'e Kopyala
```bash
# Mac'te Ã§alÄ±ÅŸtÄ±r
scp -r jensen@192.168.88.55:~/jessy-training/jessy-thor-output ./training/models/
```

### Ollama'ya Import Et
```bash
# Mac'te
cd training/models/jessy-thor-output
# GGUF'a Ã§evir ve Ollama'ya import et (ayrÄ± script gerekli)
```

## Troubleshooting

### Out of Memory
```python
# train_on_thor.py iÃ§inde deÄŸiÅŸtir:
"per_device_train_batch_size": 4,  # 8'den 4'e dÃ¼ÅŸÃ¼r
"gradient_accumulation_steps": 8,  # 4'ten 8'e Ã§Ä±kar
```

### CUDA Error
```bash
# CUDA path'i ekle
export PATH=/usr/local/cuda-13.0/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:$LD_LIBRARY_PATH
```

### Slow Training
```bash
# GPU kullanÄ±mÄ±nÄ± kontrol et
nvidia-smi

# CPU'da Ã§alÄ±ÅŸÄ±yorsa:
python3 -c "import torch; print(torch.cuda.is_available())"
```

## HÄ±zlÄ± Komutlar

```bash
# Tek komutla setup (Mac'ten)
scp training/train_on_thor.py training/datasets/jessy_maximum_*.jsonl jensen@192.168.88.55:~/jessy-training/

# Tek komutla training baÅŸlat (Thor'da)
cd ~/jessy-training && nohup python3 train_on_thor.py > training.log 2>&1 & tail -f training.log

# Model'i geri getir (Mac'ten)
scp -r jensen@192.168.88.55:~/jessy-training/jessy-thor-output ./training/models/
```

## Sonraki AdÄ±mlar

1. âœ… Training tamamlandÄ±
2. Model'i Mac'e kopyala
3. GGUF formatÄ±na Ã§evir
4. Ollama'ya import et
5. Test et!

---

**"Nothing is true, everything is permitted."**  
Including training AI on Thor's hammer! âš¡ðŸ”¨
