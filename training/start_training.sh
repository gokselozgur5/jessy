#!/bin/bash
# Quick start script for Jessy LoRA training on M2

set -e

echo "ğŸš€ Jessy LoRA Training - M2 Optimized"
echo "======================================"
echo ""

# Check if venv exists
if [ ! -d "venv" ]; then
    echo "âŒ Virtual environment not found!"
    echo "Run: python3 -m venv venv"
    exit 1
fi

# Activate venv
echo "ğŸ“¦ Activating virtual environment..."
source venv/bin/activate

# Check datasets
if [ ! -f "datasets/jessy_maximum_train.jsonl" ]; then
    echo "âŒ Training dataset not found!"
    echo "Expected: datasets/jessy_maximum_train.jsonl"
    exit 1
fi

if [ ! -f "datasets/jessy_maximum_val.jsonl" ]; then
    echo "âŒ Validation dataset not found!"
    echo "Expected: datasets/jessy_maximum_val.jsonl"
    exit 1
fi

echo "âœ… Datasets found"
echo ""

# Check if model is already downloaded
echo "ğŸ“¥ Checking model..."
python3 -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct')" 2>/dev/null && echo "âœ… Model ready" || echo "â³ Model will be downloaded (first time only)"
echo ""

# Estimate time
TRAIN_SAMPLES=$(wc -l < datasets/jessy_maximum_train.jsonl)
echo "ğŸ“Š Training Info:"
echo "   Samples: $TRAIN_SAMPLES"
echo "   Epochs: 3"
echo "   Estimated time: 6-8 hours on M2"
echo ""

# Confirm
read -p "Start training? (y/n) " -n 1 -r
echo ""
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Cancelled."
    exit 0
fi

# Create output directories
mkdir -p models/jessy-lora-m2
mkdir -p checkpoints/jessy-lora

# Start training
echo ""
echo "ğŸ¯ Starting training..."
echo "======================================"
echo ""

python3 train_lora_m2.py 2>&1 | tee training_log.txt

echo ""
echo "âœ… Training complete!"
echo "ğŸ“ Model saved to: models/jessy-lora-m2"
echo "ğŸ“ Log saved to: training_log.txt"
